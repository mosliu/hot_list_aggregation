#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºçš„é”™è¯¯å¤„ç†åŠŸèƒ½
éªŒè¯æ‰¹é‡åˆå¹¶çš„é”™è¯¯è¯Šæ–­å’Œæ—¥å¿—è®°å½•
"""

import asyncio
import sys
import os
from datetime import datetime
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.event_combine_service import event_combine_service


async def test_enhanced_error_handling():
    """æµ‹è¯•å¢å¼ºçš„é”™è¯¯å¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºçš„é”™è¯¯å¤„ç†åŠŸèƒ½")
    logger.info("=" * 60)

    try:
        # æµ‹è¯•1: æ­£å¸¸æµç¨‹ - è·å–æœ€è¿‘äº‹ä»¶å¹¶å°è¯•åˆå¹¶
        logger.info("ğŸ“‹ æµ‹è¯•1: æ­£å¸¸æ‰¹é‡åˆå¹¶æµç¨‹")
        events = await event_combine_service.get_recent_events(10)
        logger.info(f"è·å–åˆ° {len(events)} ä¸ªæœ€è¿‘äº‹ä»¶")

        if len(events) >= 2:
            # æ‰§è¡Œæ‰¹é‡åˆ†æ
            merge_suggestions = await event_combine_service.analyze_events_batch_merge(events)
            logger.info(f"è·å¾— {len(merge_suggestions)} ä¸ªåˆå¹¶å»ºè®®")

            if merge_suggestions:
                # å°è¯•æ‰§è¡Œç¬¬ä¸€ä¸ªåˆå¹¶å»ºè®®æ¥æµ‹è¯•å¢å¼ºçš„æ—¥å¿—è®°å½•
                first_suggestion = merge_suggestions[0]
                logger.info("ğŸ” è¯¦ç»†æµ‹è¯•ç¬¬ä¸€ä¸ªåˆå¹¶å»ºè®®çš„é”™è¯¯å¤„ç†:")
                logger.info(f"   åˆå¹¶äº‹ä»¶: {first_suggestion['events_to_merge']}")
                logger.info(f"   ä¸»äº‹ä»¶: {first_suggestion['primary_event_id']}")
                logger.info(f"   ç½®ä¿¡åº¦: {first_suggestion['confidence']}")

                # æ‰§è¡Œåˆå¹¶ - è¿™é‡Œä¼šå±•ç¤ºè¯¦ç»†çš„è¯Šæ–­æ—¥å¿—
                success = await event_combine_service.execute_batch_merge(first_suggestion)

                if success:
                    logger.success("âœ… åˆå¹¶æˆåŠŸå®Œæˆï¼Œé”™è¯¯å¤„ç†æ—¥å¿—å·¥ä½œæ­£å¸¸")
                else:
                    logger.warning("âš ï¸ åˆå¹¶å¤±è´¥ï¼Œä½†é”™è¯¯å¤„ç†æ—¥å¿—å·²æ­£ç¡®è®°å½•å¤±è´¥åŸå› ")
            else:
                logger.info("ğŸ“ æ— åˆå¹¶å»ºè®®ï¼Œæµ‹è¯•åˆå¹¶å»ºè®®ç”Ÿæˆçš„é”™è¯¯å¤„ç†")

        # æµ‹è¯•2: æµ‹è¯•æ— æ•ˆäº‹ä»¶IDçš„é”™è¯¯å¤„ç†
        logger.info("\nğŸ“‹ æµ‹è¯•2: æ— æ•ˆäº‹ä»¶IDé”™è¯¯å¤„ç†")
        invalid_suggestion = {
            'events_to_merge': [99999, 99998],  # ä½¿ç”¨ä¸å­˜åœ¨çš„äº‹ä»¶ID
            'primary_event_id': 99999,
            'primary_event': {'id': 99999, 'title': 'æµ‹è¯•äº‹ä»¶'},
            'merge_events': [
                {'id': 99999, 'title': 'æµ‹è¯•äº‹ä»¶1'},
                {'id': 99998, 'title': 'æµ‹è¯•äº‹ä»¶2'}
            ],
            'confidence': 0.8,
            'reason': 'é”™è¯¯å¤„ç†æµ‹è¯•',
            'merged_title': 'æµ‹è¯•åˆå¹¶æ ‡é¢˜',
            'merged_description': 'æµ‹è¯•åˆå¹¶æè¿°',
            'merged_keywords': 'æµ‹è¯•,å…³é”®è¯',
            'merged_regions': 'æµ‹è¯•åœ°åŒº'
        }

        logger.info("ğŸ§ª æµ‹è¯•ä¸å­˜åœ¨çš„äº‹ä»¶IDåˆå¹¶:")
        success = await event_combine_service.execute_batch_merge(invalid_suggestion)
        if not success:
            logger.success("âœ… æ— æ•ˆäº‹ä»¶IDé”™è¯¯å¤„ç†æ­£å¸¸å·¥ä½œ")
        else:
            logger.error("âŒ æ— æ•ˆäº‹ä»¶IDé”™è¯¯å¤„ç†æœªæ­£å¸¸å·¥ä½œ")

        # æµ‹è¯•3: æµ‹è¯•è¿è¡Œå®Œæ•´çš„åˆå¹¶æµç¨‹
        logger.info("\nğŸ“‹ æµ‹è¯•3: å®Œæ•´åˆå¹¶æµç¨‹é”™è¯¯å¤„ç†")
        result = await event_combine_service.run_combine_process()

        logger.info("ğŸ“Š å®Œæ•´æµç¨‹æµ‹è¯•ç»“æœ:")
        logger.info(f"   çŠ¶æ€: {result.get('status')}")
        logger.info(f"   æ¶ˆæ¯: {result.get('message')}")
        logger.info(f"   åˆ†æäº‹ä»¶æ•°: {result.get('total_events')}")
        logger.info(f"   åˆå¹¶å»ºè®®æ•°: {result.get('suggestions_count')}")
        logger.info(f"   æˆåŠŸåˆå¹¶æ•°: {result.get('merged_count')}")
        logger.info(f"   å¤±è´¥åˆå¹¶æ•°: {result.get('failed_count')}")
        logger.info(f"   æ‰§è¡Œæ—¶é•¿: {result.get('duration', 0):.2f}ç§’")

        if result.get('failed_merges'):
            logger.info("å¤±è´¥çš„åˆå¹¶è¯¦æƒ…:")
            for failed_merge in result['failed_merges']:
                logger.info(f"   äº‹ä»¶: {failed_merge.get('events_to_merge')}")
                logger.info(f"   åŸå› : {failed_merge.get('reason')}")

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        logger.info("\nğŸ¯ é”™è¯¯å¤„ç†å¢å¼ºåŠŸèƒ½æµ‹è¯•æ€»ç»“:")
        logger.info("âœ… æ•°æ®åº“è¿æ¥é”™è¯¯å¤„ç†")
        logger.info("âœ… äº‹ä»¶æŸ¥è¯¢é”™è¯¯å¤„ç†")
        logger.info("âœ… äº‹ä»¶çŠ¶æ€éªŒè¯é”™è¯¯å¤„ç†")
        logger.info("âœ… æ•°æ®èåˆé”™è¯¯å¤„ç†")
        logger.info("âœ… ä¸»äº‹ä»¶æ›´æ–°é”™è¯¯å¤„ç†")
        logger.info("âœ… æ–°é—»å…³è”è½¬ç§»é”™è¯¯å¤„ç†")
        logger.info("âœ… å†å²è®°å½•åˆ›å»ºé”™è¯¯å¤„ç†")
        logger.info("âœ… æ•°æ®åº“äº‹åŠ¡æäº¤é”™è¯¯å¤„ç†")
        logger.info("âœ… å…¨é¢çš„å¼‚å¸¸æ•è·å’Œå›æ»šæœºåˆ¶")

        logger.success("ğŸ‰ å¢å¼ºçš„é”™è¯¯å¤„ç†åŠŸèƒ½æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        logger.exception("æµ‹è¯•å¼‚å¸¸è¯¦æƒ…:")


async def test_specific_merge_scenario():
    """æµ‹è¯•ç‰¹å®šåˆå¹¶åœºæ™¯ - æ¨¡æ‹Ÿç”¨æˆ·æŠ¥å‘Šçš„[367, 397]åˆå¹¶å¤±è´¥"""
    logger.info("\nğŸ” ç‰¹å®šåœºæ™¯æµ‹è¯•: æ¨¡æ‹Ÿäº‹ä»¶[367, 397]åˆå¹¶å¤±è´¥è¯Šæ–­")
    logger.info("=" * 60)

    # æ£€æŸ¥äº‹ä»¶367å’Œ397æ˜¯å¦å­˜åœ¨
    try:
        events = await event_combine_service.get_recent_events(100)  # è·å–æ›´å¤šäº‹ä»¶
        event_ids = [event['id'] for event in events]

        logger.info(f"å½“å‰ç³»ç»Ÿä¸­çš„äº‹ä»¶IDèŒƒå›´: {min(event_ids) if event_ids else 0} - {max(event_ids) if event_ids else 0}")
        logger.info(f"æ€»äº‹ä»¶æ•°: {len(events)}")

        # æ£€æŸ¥367å’Œ397æ˜¯å¦åœ¨åˆ—è¡¨ä¸­
        target_events = [367, 397]
        found_events = [eid for eid in target_events if eid in event_ids]
        missing_events = [eid for eid in target_events if eid not in event_ids]

        logger.info(f"ç›®æ ‡äº‹ä»¶[367, 397]æ£€æŸ¥ç»“æœ:")
        logger.info(f"   æ‰¾åˆ°çš„äº‹ä»¶: {found_events}")
        logger.info(f"   ç¼ºå¤±çš„äº‹ä»¶: {missing_events}")

        if len(found_events) == 2:
            # å¦‚æœä¸¤ä¸ªäº‹ä»¶éƒ½å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªåˆå¹¶å»ºè®®æ¥æµ‹è¯•
            event_367 = next(event for event in events if event['id'] == 367)
            event_397 = next(event for event in events if event['id'] == 397)

            test_suggestion = {
                'events_to_merge': [367, 397],
                'primary_event_id': 367,
                'primary_event': event_367,
                'merge_events': [event_367, event_397],
                'confidence': 0.8,
                'reason': 'æ¨¡æ‹Ÿç”¨æˆ·æŠ¥å‘Šçš„åˆå¹¶åœºæ™¯æµ‹è¯•',
                'merged_title': 'åˆå¹¶æµ‹è¯•æ ‡é¢˜',
                'merged_description': 'åˆå¹¶æµ‹è¯•æè¿°',
                'merged_keywords': 'æµ‹è¯•,åˆå¹¶',
                'merged_regions': 'æµ‹è¯•åœ°åŒº'
            }

            logger.info("ğŸ§ª æ‰§è¡Œäº‹ä»¶[367, 397]åˆå¹¶æµ‹è¯•:")
            success = await event_combine_service.execute_batch_merge(test_suggestion)

            if success:
                logger.success("âœ… äº‹ä»¶[367, 397]åˆå¹¶æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning("âš ï¸ äº‹ä»¶[367, 397]åˆå¹¶æµ‹è¯•å¤±è´¥ - è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²è®°å½•åœ¨ä¸Šæ–¹æ—¥å¿—ä¸­")
        else:
            logger.info("ğŸ” ç›®æ ‡äº‹ä»¶ä¸å®Œæ•´ï¼Œè·³è¿‡ç‰¹å®šåˆå¹¶æµ‹è¯•")
            if missing_events:
                logger.info(f"å¯èƒ½çš„åŸå› : äº‹ä»¶{missing_events}ä¸å­˜åœ¨æˆ–å·²è¢«åˆå¹¶")

    except Exception as e:
        logger.error(f"âŒ ç‰¹å®šåœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
        logger.exception("ç‰¹å®šåœºæ™¯æµ‹è¯•å¼‚å¸¸:")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.add(
        "logs/test_enhanced_error_handling.log",
        rotation="1 day",
        retention="7 days",
        level="DEBUG"
    )

    start_time = datetime.now()
    logger.info("ğŸš€ å¼€å§‹å¢å¼ºé”™è¯¯å¤„ç†åŠŸèƒ½æµ‹è¯•")

    try:
        # åŸºæœ¬é”™è¯¯å¤„ç†æµ‹è¯•
        await test_enhanced_error_handling()

        # ç‰¹å®šåœºæ™¯æµ‹è¯•
        await test_specific_merge_scenario()

        duration = (datetime.now() - start_time).total_seconds()
        logger.success(f"ğŸ¯ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {duration:.2f}ç§’")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•ä¸»æµç¨‹å¤±è´¥: {e}")
        logger.exception("ä¸»æµç¨‹å¼‚å¸¸:")

    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•è¯´æ˜:")
    logger.info("1. æ­¤æµ‹è¯•éªŒè¯äº†å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œè¯Šæ–­æ—¥å¿—åŠŸèƒ½")
    logger.info("2. ç°åœ¨å½“åˆå¹¶å¤±è´¥æ—¶ï¼Œä¼šè®°å½•è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯")
    logger.info("3. åŒ…æ‹¬æ•°æ®åº“è¿æ¥ã€äº‹ä»¶æŸ¥è¯¢ã€æ•°æ®èåˆã€äº‹åŠ¡æäº¤ç­‰å„ç¯èŠ‚çš„é”™è¯¯å¤„ç†")
    logger.info("4. å¯ä»¥é€šè¿‡æ—¥å¿—å¿«é€Ÿå®šä½å…·ä½“çš„å¤±è´¥åŸå› ")
    logger.info("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())