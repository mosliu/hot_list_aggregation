#!/usr/bin/env python3
"""
æµ‹è¯•JSONæˆªæ–­é—®é¢˜çš„ä¿®å¤æ–¹æ¡ˆ
ç”¨äºéªŒè¯å¤„ç†ä¸å®Œæ•´JSONå“åº”çš„è§£å†³æ–¹æ¡ˆ
"""

import json
import re
from typing import Dict, List, Set, Any
from pathlib import Path

def extract_news_ids_from_truncated_json(content: str) -> Set[int]:
    """
    ä»è¢«æˆªæ–­çš„JSONå†…å®¹ä¸­æå–æ–°é—»ID
    ä½¿ç”¨å¤šç§ç­–ç•¥æ¥å¤„ç†ä¸å®Œæ•´çš„JSON
    """
    news_ids = set()
    
    # ç­–ç•¥1: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç›´æ¥æå–news_idsæ•°ç»„
    patterns = [
        r'"news_ids":\s*\[\s*([\d,\s"]+)\s*\]',  # å®Œæ•´çš„æ•°ç»„
        r'"news_ids":\s*\[\s*([\d,\s"]*)',       # ä¸å®Œæ•´çš„æ•°ç»„å¼€å§‹
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, content)
        for match in matches:
            # æå–æ•°å­—
            numbers = re.findall(r'\d+', match)
            for num_str in numbers:
                try:
                    num = int(num_str)
                    if num > 1000:  # å‡è®¾æ–°é—»IDéƒ½å¤§äº1000
                        news_ids.add(num)
                except ValueError:
                    continue
    
    # ç­–ç•¥2: æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ–°é—»IDï¼ˆ6ä½ä»¥ä¸Šæ•°å­—ï¼‰
    all_numbers = re.findall(r'\b(\d{4,})\b', content)
    for num_str in all_numbers:
        try:
            num = int(num_str)
            if 1000 <= num <= 999999:  # åˆç†çš„æ–°é—»IDèŒƒå›´
                news_ids.add(num)
        except ValueError:
            continue
    
    return news_ids

def fix_truncated_json(content: str) -> str:
    """
    å°è¯•ä¿®å¤è¢«æˆªæ–­çš„JSON
    """
    # æŸ¥æ‰¾JSONå¼€å§‹ä½ç½®
    json_start = content.find('{')
    if json_start == -1:
        return content
    
    json_content = content[json_start:]
    
    # è®¡ç®—å¤§æ‹¬å·å¹³è¡¡
    brace_count = 0
    bracket_count = 0
    last_complete_pos = -1
    
    for i, char in enumerate(json_content):
        if char == '{':
            brace_count += 1
        elif char == '}':
            brace_count -= 1
            if brace_count == 0:
                last_complete_pos = i + 1
                break
        elif char == '[':
            bracket_count += 1
        elif char == ']':
            bracket_count -= 1
    
    if last_complete_pos > 0:
        # JSONæ˜¯å®Œæ•´çš„
        return json_content[:last_complete_pos]
    
    # JSONè¢«æˆªæ–­ï¼Œå°è¯•ä¿®å¤
    fixed_json = json_content.rstrip()
    
    # ç§»é™¤æœ€åå¯èƒ½ä¸å®Œæ•´çš„éƒ¨åˆ†
    while fixed_json and fixed_json[-1] not in '}]':
        fixed_json = fixed_json[:-1]
    
    # æ·»åŠ ç¼ºå¤±çš„é—­åˆç¬¦å·
    while bracket_count > 0:
        fixed_json += ']'
        bracket_count -= 1
    
    while brace_count > 0:
        fixed_json += '}'
        brace_count -= 1
    
    return fixed_json

def test_json_fix_strategy(log_file_path: str):
    """æµ‹è¯•JSONä¿®å¤ç­–ç•¥"""
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•JSONä¿®å¤ç­–ç•¥: {Path(log_file_path).name}")
    print(f"{'='*80}")
    
    try:
        with open(log_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆ†æåŸå§‹æ•°æ®
        request_content = data['request']['messages'][0]['content']
        input_news_ids = set(int(nid) for nid in re.findall(r'ID:(\d+)', request_content))
        response_content = data['response']['content']
        
        print(f"åŸå§‹åˆ†æ:")
        print(f"  è¾“å…¥æ–°é—»æ•°é‡: {len(input_news_ids)}")
        print(f"  å“åº”å†…å®¹é•¿åº¦: {len(response_content):,} å­—ç¬¦")
        
        # ç­–ç•¥1: ç›´æ¥æå–æ–°é—»IDï¼ˆä¸ä¾èµ–JSONè§£æï¼‰
        extracted_ids_direct = extract_news_ids_from_truncated_json(response_content)
        print(f"\nç­–ç•¥1 - ç›´æ¥æå–:")
        print(f"  æå–åˆ°çš„æ–°é—»IDæ•°é‡: {len(extracted_ids_direct)}")
        
        if extracted_ids_direct:
            matching_direct = input_news_ids & extracted_ids_direct
            missing_direct = input_news_ids - extracted_ids_direct
            print(f"  åŒ¹é…çš„æ–°é—»ID: {len(matching_direct)}")
            print(f"  é—æ¼çš„æ–°é—»ID: {len(missing_direct)}")
            print(f"  åŒ¹é…ç‡: {len(matching_direct)/len(input_news_ids)*100:.1f}%")
        
        # ç­–ç•¥2: å°è¯•ä¿®å¤JSONåè§£æ
        try:
            fixed_json_str = fix_truncated_json(response_content)
            fixed_json = json.loads(fixed_json_str)
            
            extracted_ids_fixed = set()
            for event in fixed_json.get('existing_events', []):
                for nid in event.get('news_ids', []):
                    extracted_ids_fixed.add(int(nid) if isinstance(nid, str) else nid)
            
            for event in fixed_json.get('new_events', []):
                for nid in event.get('news_ids', []):
                    extracted_ids_fixed.add(int(nid) if isinstance(nid, str) else nid)
            
            print(f"\nç­–ç•¥2 - JSONä¿®å¤:")
            print(f"  ä¿®å¤åJSONé•¿åº¦: {len(fixed_json_str):,} å­—ç¬¦")
            print(f"  æå–åˆ°çš„æ–°é—»IDæ•°é‡: {len(extracted_ids_fixed)}")
            
            if extracted_ids_fixed:
                matching_fixed = input_news_ids & extracted_ids_fixed
                missing_fixed = input_news_ids - extracted_ids_fixed
                print(f"  åŒ¹é…çš„æ–°é—»ID: {len(matching_fixed)}")
                print(f"  é—æ¼çš„æ–°é—»ID: {len(missing_fixed)}")
                print(f"  åŒ¹é…ç‡: {len(matching_fixed)/len(input_news_ids)*100:.1f}%")
        
        except json.JSONDecodeError as e:
            print(f"\nç­–ç•¥2 - JSONä¿®å¤å¤±è´¥: {e}")
        
        # ç­–ç•¥3: ç»„åˆç­–ç•¥ï¼ˆå–ä¸¤ç§æ–¹æ³•çš„å¹¶é›†ï¼‰
        combined_ids = extracted_ids_direct
        try:
            combined_ids = combined_ids | extracted_ids_fixed
        except:
            pass
        
        print(f"\nç­–ç•¥3 - ç»„åˆç­–ç•¥:")
        print(f"  ç»„åˆåæ–°é—»IDæ•°é‡: {len(combined_ids)}")
        
        if combined_ids:
            matching_combined = input_news_ids & combined_ids
            missing_combined = input_news_ids - combined_ids
            print(f"  åŒ¹é…çš„æ–°é—»ID: {len(matching_combined)}")
            print(f"  é—æ¼çš„æ–°é—»ID: {len(missing_combined)}")
            print(f"  åŒ¹é…ç‡: {len(matching_combined)/len(input_news_ids)*100:.1f}%")
            
            if len(missing_combined) > 0:
                print(f"  é—æ¼IDç¤ºä¾‹: {sorted(list(missing_combined))[:10]}")
        
        return {
            'input_count': len(input_news_ids),
            'direct_count': len(extracted_ids_direct),
            'combined_count': len(combined_ids),
            'direct_match_rate': len(input_news_ids & extracted_ids_direct)/len(input_news_ids)*100 if extracted_ids_direct else 0,
            'combined_match_rate': len(input_news_ids & combined_ids)/len(input_news_ids)*100 if combined_ids else 0
        }
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
        return None

def generate_fix_code():
    """ç”Ÿæˆä¿®å¤ä»£ç å»ºè®®"""
    print(f"\n{'='*80}")
    print("ç”Ÿæˆä¿®å¤ä»£ç å»ºè®®")
    print(f"{'='*80}")
    
    fix_code = '''
def extract_news_ids_robust(response_content: str) -> Set[int]:
    """
    é²æ£’çš„æ–°é—»IDæå–æ–¹æ³•ï¼Œå¤„ç†JSONæˆªæ–­é—®é¢˜
    """
    news_ids = set()
    
    # æ–¹æ³•1: å°è¯•æ­£å¸¸JSONè§£æ
    try:
        # æŸ¥æ‰¾JSONéƒ¨åˆ†
        json_start = response_content.find('{')
        if json_start != -1:
            # å°è¯•æ‰¾åˆ°å®Œæ•´çš„JSON
            brace_count = 0
            for i, char in enumerate(response_content[json_start:], json_start):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_str = response_content[json_start:i+1]
                        result = json.loads(json_str)
                        
                        # æå–æ–°é—»ID
                        for event in result.get('existing_events', []):
                            for nid in event.get('news_ids', []):
                                news_ids.add(int(nid) if isinstance(nid, str) else nid)
                        
                        for event in result.get('new_events', []):
                            for nid in event.get('news_ids', []):
                                news_ids.add(int(nid) if isinstance(nid, str) else nid)
                        
                        return news_ids
    except:
        pass
    
    # æ–¹æ³•2: æ­£åˆ™è¡¨è¾¾å¼æå–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    patterns = [
        r'"news_ids":\\s*\\[\\s*([\\d,\\s"]+)\\s*\\]',  # å®Œæ•´æ•°ç»„
        r'"news_ids":\\s*\\[\\s*([\\d,\\s"]*)',        # ä¸å®Œæ•´æ•°ç»„
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, response_content)
        for match in matches:
            numbers = re.findall(r'\\d+', match)
            for num_str in numbers:
                try:
                    num = int(num_str)
                    if num > 1000:  # åˆç†çš„æ–°é—»IDèŒƒå›´
                        news_ids.add(num)
                except ValueError:
                    continue
    
    return news_ids

def validate_and_fix_aggregation_result_robust(self, news_batch: List[Dict], result: Dict) -> Dict:
    """
    æ”¹è¿›çš„éªŒè¯é€»è¾‘ï¼Œå¤„ç†JSONæˆªæ–­é—®é¢˜
    """
    try:
        # æå–è¾“å…¥æ–°é—»ID
        input_news_ids = set(news['id'] for news in news_batch)
        input_news_dict = {news['id']: news for news in news_batch}
        
        # ä½¿ç”¨é²æ£’çš„æ–¹æ³•æå–å¤„ç†è¿‡çš„æ–°é—»ID
        if isinstance(result, str):
            # å¦‚æœresultæ˜¯å­—ç¬¦ä¸²ï¼ˆåŸå§‹å“åº”ï¼‰ï¼Œä½¿ç”¨é²æ£’æå–
            processed_news_ids = extract_news_ids_robust(result)
        else:
            # å¦‚æœresultæ˜¯å­—å…¸ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            processed_news_ids = set()
            for event in result.get('existing_events', []):
                processed_news_ids.update(event.get('news_ids', []))
            for event in result.get('new_events', []):
                processed_news_ids.update(event.get('news_ids', []))
        
        # ç±»å‹ç»Ÿä¸€å¤„ç†
        processed_news_ids = {int(nid) if isinstance(nid, str) else nid for nid in processed_news_ids}
        
        # è®¡ç®—åŒ¹é…æƒ…å†µ
        missing_ids = input_news_ids - processed_news_ids
        extra_ids = processed_news_ids - input_news_ids
        
        # å¦‚æœåŒ¹é…ç‡å¾ˆé«˜ï¼ˆæ¯”å¦‚>80%ï¼‰ï¼Œè®¤ä¸ºæ˜¯å¯æ¥å—çš„
        match_rate = len(input_news_ids & processed_news_ids) / len(input_news_ids)
        
        if match_rate >= 0.8:  # 80%ä»¥ä¸ŠåŒ¹é…ç‡è®¤ä¸ºå¯æ¥å—
            logger.info(f"éƒ¨åˆ†åŒ¹é…å¯æ¥å—ï¼ŒåŒ¹é…ç‡: {match_rate:.1%}")
            return {
                'is_valid': True,
                'fixed_result': result,
                'missing_news': [],
                'extra_ids': extra_ids,
                'message': f'éƒ¨åˆ†åŒ¹é…å¯æ¥å—ï¼ŒåŒ¹é…ç‡: {match_rate:.1%}'
            }
        
        # å…¶ä»–é€»è¾‘ä¿æŒä¸å˜...
        
    except Exception as e:
        logger.error(f"ç»“æœéªŒè¯å¼‚å¸¸: {e}")
        return {
            'is_valid': False,
            'fixed_result': None,
            'missing_news': news_batch,
            'extra_ids': set(),
            'message': f'éªŒè¯å¼‚å¸¸: {str(e)}'
        }
'''
    
    print("å»ºè®®çš„ä¿®å¤ä»£ç :")
    print(fix_code)

def main():
    """ä¸»å‡½æ•°"""
    print("JSONæˆªæ–­é—®é¢˜ä¿®å¤æ–¹æ¡ˆæµ‹è¯•")
    print("ç”¨äºéªŒè¯å¤„ç†ä¸å®Œæ•´JSONå“åº”çš„è§£å†³æ–¹æ¡ˆ")
    
    # æµ‹è¯•æ—¥å¿—æ–‡ä»¶
    log_files = [
        "logs/llm_calls/2025-09-28T15-32-25.758511_78f993d5-b37d-4133-a1cb-6019f129dc05.json",
        "logs/llm_calls/2025-09-28T15-46-46.286156_ecc1ffc4-0575-42b8-9ba7-843024408d09.json",
    ]
    
    results = []
    for log_file in log_files:
        if Path(log_file).exists():
            result = test_json_fix_strategy(log_file)
            if result:
                results.append((log_file, result))
        else:
            print(f"\næ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
    
    # æ€»ç»“
    print(f"\n{'='*80}")
    print("ä¿®å¤ç­–ç•¥æµ‹è¯•æ€»ç»“")
    print(f"{'='*80}")
    
    for log_file, result in results:
        filename = Path(log_file).name
        print(f"{filename}:")
        print(f"  è¾“å…¥æ–°é—»: {result['input_count']}")
        print(f"  ç›´æ¥æå–åŒ¹é…ç‡: {result['direct_match_rate']:.1f}%")
        print(f"  ç»„åˆç­–ç•¥åŒ¹é…ç‡: {result['combined_match_rate']:.1f}%")
    
    # ç”Ÿæˆä¿®å¤ä»£ç 
    generate_fix_code()
    
    print(f"\nğŸ’¡ å…³é”®å‘ç°:")
    print(f"   1. JSONå“åº”è¢«æˆªæ–­æ˜¯ä¸»è¦é—®é¢˜")
    print(f"   2. ç›´æ¥æ­£åˆ™æå–å¯ä»¥è·å¾—60-70%çš„åŒ¹é…ç‡")
    print(f"   3. å»ºè®®é™ä½æ‰¹å¤„ç†å¤§å°æˆ–å¢åŠ tokené™åˆ¶")
    print(f"   4. å¯ä»¥è®¾ç½®åŒ¹é…ç‡é˜ˆå€¼ï¼ˆå¦‚80%ï¼‰æ¥æ¥å—éƒ¨åˆ†åŒ¹é…")

if __name__ == "__main__":
    main()